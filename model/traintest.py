# -*- coding: utf-8 -*-
"""traintest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J_zVPA1UxVJOXCsza2BUeoAorrNIsWE1
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

def trains(epochs, model, lr, save_loss, save_acc, trainDataLoader, valDataLoader):
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=lr)
  save_loss = save_loss
  save_acc = save_acc
  trainDataLoader = trainDataLoader
  testDataLoader = valDataLoader
  for epoch in range(epochs):
    model.train()
    current_loss = 0.0
    current_corrects = 0
    for batch_idx, (inputs, labels) in enumerate(trainDataLoader):
      # print(batch_idx)
      inputs = inputs.cuda()
      labels = labels.cuda()
      model.cuda()
      optimizer.zero_grad()

      with torch.set_grad_enabled(True):
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()
      
      current_loss += loss.item() * inputs.size(0)
      current_corrects += torch.sum(preds == labels.data)

    save_loss['train'] += [current_loss / len(trainDataLoader.dataset)]
    save_acc['train'] += [current_corrects.float() / len(trainDataLoader.dataset)]
    # pretty print
    print(f"Epoch:{epoch} -- Phase:{'train'} -- Loss:{save_loss['train'][-1]:.2f} -- Acc:{save_acc['train'][-1]*100:.2f}")

    model.eval()
    current_loss = 0.0
    current_corrects = 0
    for batch_idx, (inputs, labels) in enumerate(testDataLoader):
      # print(batch_idx)
      inputs = inputs.cuda()
      labels = labels.cuda()
      optimizer.zero_grad()

      with torch.set_grad_enabled(False):
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)

      current_loss += loss.item() * inputs.size(0)
      current_corrects += torch.sum(preds == labels.data)

    save_loss['val'] += [current_loss / len(testDataLoader.dataset)]
    save_acc['val'] += [current_corrects.float() / len(testDataLoader.dataset)]
    # pretty print
    print(f"Epoch:{epoch} -- Phase:{'val'} -- Loss:{save_loss['val'][-1]:.2f} -- Acc:{save_acc['val'][-1]*100:.2f}")

def tests(model, test_loss, test_acc, testDataLoader):
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.Adam(model.parameters(), lr=5.5e-5)
  model.eval()
  current_loss = 0.0
  current_corrects = 0
  for batch_idx, (inputs, labels) in enumerate(testDataLoader):
    inputs = inputs.cuda()
    labels = labels.cuda()
    optimizer.zero_grad()

    with torch.set_grad_enabled(False):
      outputs = model(inputs)
      _, preds = torch.max(outputs, 1)
      loss = criterion(outputs, labels)

    current_loss += loss.item() * inputs.size(0)
    current_corrects += torch.sum(preds == labels.data)

  test_loss = current_loss / len(testDataLoader.dataset)
  test_acc = current_corrects.float() / len(testDataLoader.dataset)
  # pretty print
  print(f"Epoch:{1} -- Phase:{'test'} -- Loss:{test_loss:.2f} -- Acc:{test_acc*100:.2f}")